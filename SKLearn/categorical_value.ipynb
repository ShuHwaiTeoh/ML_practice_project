{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "categorical_value",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lNfypVsXpLbX_ltKDq6lupTBEsxEoo_K",
      "authorship_tag": "ABX9TyMtJ4YeQ7QqhccYNzwzoTvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuHwaiTeoh/ML_practice_project/blob/master/SKLearn/categorical_value.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9py4oCu3ev7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path of the file to read\n",
        "file_path = '/content/drive/My Drive/melb_data.csv'\n",
        "\n",
        "# read the file into a dataframe\n",
        "data = pd.read_csv(file_path, encoding ='Windows-1252')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpXTH6TiioUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.Price\n",
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZRhYeZAikn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop target column from dataset\n",
        "X = data.drop(['Price'], axis=1)\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FykZ_YSSgbni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-RMr_N3fuXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view the data of categorical variables\n",
        "ob = X_train.select_dtypes(include=['object'])\n",
        "print(ob.head())\n",
        "\n",
        "# Get list of categorical variables\n",
        "c = (X_train.dtypes == 'object')\n",
        "object_cols = list(c[c].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKkELzjfpvYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop Categorical Variables\n",
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwEAOp_5rPZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Columns that can be safely label encoded\n",
        "good_label_cols = [col for col in object_cols if set(X_train[col]) == set(X_valid[col])]\n",
        "        \n",
        "# Problematic columns that will be dropped from the dataset\n",
        "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
        "\n",
        "# Drop categorical columns that will not be encoded\n",
        "good_X_train = X_train.drop(bad_label_cols, axis=1)\n",
        "good_X_valid = X_valid.drop(bad_label_cols, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0jmdTwS6KuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Make copy to avoid changing original data \n",
        "label_X_train = good_X_train.copy()\n",
        "label_X_valid = good_X_valid.copy()\n",
        "\n",
        "# Apply label encoder to each column with categorical data\n",
        "# Randomly assign each unique value to a different integer.\n",
        "label_encoder = LabelEncoder()\n",
        "for col in good_label_cols:\n",
        "    label_X_train[col] = label_encoder.fit_transform(good_X_train[col])\n",
        "    label_X_valid[col] = label_encoder.transform(good_X_valid[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDa5kMQkp48H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Select Date as the ordinal variables \n",
        "label_X_train = good_X_train.copy()\n",
        "label_X_valid = good_X_valid.copy()\n",
        "\n",
        "# Ordinal encoding\n",
        "# Encode values of ordinal variables with value between 0 and n_classes-1\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "for col in good_label_cols:\n",
        "  label_X_train[ordinal_cols] = ordinal_encoder.fit_transform(good_X_train[ordinal_cols])\n",
        "  label_X_valid[ordinal_cols] = ordinal_encoder.transform(good_X_valid[ordinal_cols])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTKiiZOAwu_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of unique entries in each column with categorical data\n",
        "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
        "d = dict(zip(object_cols, object_nunique))\n",
        "\n",
        "# Print number of unique entries by column, in ascending order\n",
        "sorted(d.items(), key=lambda x: x[1])\n",
        "\n",
        "# Columns that will be one-hot encoded\n",
        "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
        "\n",
        "# Columns that will be dropped from the dataset\n",
        "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtDea8Aw89LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Apply one-hot encoder to each column with categorical data\n",
        "# handle_unknown='ignore': avoid errors when the validation data contains classes that aren't represented in the training data\n",
        "# sparse=False: ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_valid.index = X_valid.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}